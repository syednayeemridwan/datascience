{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define a grid of hyperparameters corresponding to a Python dictionary called params_dt with:\n",
    "- the key 'max_depth' set to a list of values 2, 3, and 4\n",
    "- the key 'min_samples_leaf' set to a list of values 0.12, 0.14, 0.16, 0.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define params_dt\n",
    "# params_dt = {\n",
    "#     'max_depth' : [2, 3,  4],\n",
    "#     'min_samples_leaf' : [0.12, 0.14, 0.16, 0.18]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import GridSearchCV from sklearn.model_selection.\n",
    "- Instantiate a GridSearchCV object using 5-fold CV by setting the parameters:\n",
    "- estimator to dt, param_grid to params_dt and\n",
    "- scoring to 'roc_auc'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import GridSearchCV\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Instantiate grid_dt\n",
    "# grid_dt = GridSearchCV(estimator=dt,\n",
    "#                        param_grid=params_dt,\n",
    "#                        scoring='roc_auc',\n",
    "#                        cv=5,\n",
    "#                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import roc_auc_score from sklearn.metrics.\n",
    "- Extract the .best_estimator_ attribute from grid_dt and assign it to best_model.\n",
    "- Predict the test set probabilities of obtaining the positive class y_pred_proba.\n",
    "- Compute the test set ROC AUC score test_roc_auc of best_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import roc_auc_score from sklearn.metrics\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# # Extract the best estimator\n",
    "# best_model = grid_dt.best_estimator_\n",
    "\n",
    "# # Predict the test set probabilities of the positive class\n",
    "# y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# # Compute test_roc_auc\n",
    "# test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# # Print test_roc_auc\n",
    "# print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define a grid of hyperparameters corresponding to a Python dictionary called params_rf with:\n",
    "- the key 'n_estimators' set to a list of values 100, 350, 500\n",
    "- the key 'max_features' set to a list of values 'log2', 'auto', 'sqrt'\n",
    "- the key 'min_samples_leaf' set to a list of values 2, 10, 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the dictionary 'params_rf'\n",
    "# params_rf = {\n",
    "#     'n_estimators' : [100, 350, 500],\n",
    "#     'max_features' : ['log2', 'auto', 'sqrt'],\n",
    "#     'min_samples_leaf' : [2, 10, 30]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import GridSearchCV from sklearn.model_selection.\n",
    "- Instantiate a GridSearchCV object using 3-fold CV by using negative mean squared error as the scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import GridSearchCV\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Instantiate grid_rf\n",
    "# grid_rf = GridSearchCV(estimator=rf,\n",
    "#                        param_grid=params_rf,\n",
    "#                        scoring='neg_mean_squared_error',\n",
    "#                        cv=3,\n",
    "#                        verbose=1,\n",
    "#                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import mean_squared_error as MSE from sklearn.metrics.\n",
    "- Extract the best estimator from grid_rf and assign it to best_model.\n",
    "- Predict best_model's test set labels and assign the result to y_pred.\n",
    "- Compute best_model's test set RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import mean_squared_error from sklearn.metrics as MSE \n",
    "# from sklearn.metrics import mean_squared_error as MSE \n",
    "\n",
    "# # Extract the best estimator\n",
    "# best_model = grid_rf.best_estimator_\n",
    "\n",
    "# # Predict test set labels\n",
    "# y_pred = best_model.predict(X_test)\n",
    "\n",
    "# # Compute rmse_test\n",
    "# rmse_test = MSE(y_test, y_pred) ** (1/2)\n",
    "\n",
    "# # Print rmse_test\n",
    "# print('Test RMSE of best model: {:.3f}'.format(rmse_test)) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fef59229a6e1ff5434759995be53a28a25493efd6d26eb6c004eefe62e31083"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('env_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
