{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import DecisionTreeClassifier from sklearn.tree.\n",
    "- Instantiate a DecisionTreeClassifier dt of maximum depth equal to 6.\n",
    "- Fit dt to the training set.\n",
    "- Predict the test set labels and assign the result to y_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import DecisionTreeClassifier from sklearn.tree\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# # Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6\n",
    "# dt = DecisionTreeClassifier(max_depth = 6, random_state=SEED)\n",
    "\n",
    "# # Fit dt to the training set\n",
    "# dt.fit(X_train, y_train)\n",
    "\n",
    "# # Predict test set labels\n",
    "# y_pred = dt.predict(X_test)\n",
    "# print(y_pred[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the function accuracy_score from sklearn.metrics.\n",
    "- Predict the test set labels and assign the obtained array to y_pred.\n",
    "- Evaluate the test set accuracy score of dt by calling accuracy_score() and assign the value to acc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import accuracy_score\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Predict test set labels\n",
    "# y_pred = dt.predict(X_test)\n",
    "\n",
    "# # Compute test set accuracy  \n",
    "# acc = accuracy_score(y_test, y_pred)\n",
    "# print(\"Test set accuracy: {:.2f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import LogisticRegression from sklearn.linear_model.\n",
    "- Instantiate a LogisticRegression model and assign it to logreg.\n",
    "- Fit logreg to the training set.\n",
    "- Review the plot generated by plot_labeled_decision_regions()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "def plot_labeled_decision_regions(X,y, models):\n",
    "    '''Function producing a scatter plot of the instances contained \n",
    "    in the 2D dataset (X,y) along with the decision \n",
    "    regions of two trained classification models contained in the\n",
    "    list 'models'.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pandas DataFrame corresponding to two numerical features \n",
    "    y: pandas Series corresponding the class labels\n",
    "    models: list containing two trained classifiers \n",
    "    \n",
    "    '''\n",
    "    if len(models) != 2:\n",
    "        raise Exception('''Models should be a list containing only two trained classifiers.''')\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        raise Exception('''X has to be a pandas DataFrame with two numerical features.''')\n",
    "    if not isinstance(y, pd.Series):\n",
    "        raise Exception('''y has to be a pandas Series corresponding to the labels.''')\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10.0, 5), sharey=True)\n",
    "    for i, model in enumerate(models):\n",
    "        plot_decision_regions(X.values, y.values, model, legend= 2, ax = ax[i])\n",
    "        ax[i].set_title(model.__class__.__name__)\n",
    "        ax[i].set_xlabel(X.columns[0])\n",
    "        if i == 0:\n",
    "            ax[i].set_ylabel(X.columns[1])\n",
    "            ax[i].set_ylim(X.values[:,1].min(), X.values[:,1].max())\n",
    "            ax[i].set_xlim(X.values[:,0].min(), X.values[:,0].max())\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import LogisticRegression from sklearn.linear_model\n",
    "# from sklearn.linear_model import  LogisticRegression\n",
    "\n",
    "# # Instatiate logreg\n",
    "# logreg = LogisticRegression(random_state=1)\n",
    "\n",
    "# # Fit logreg to the training set\n",
    "# logreg.fit(X_train, y_train)\n",
    "\n",
    "# # Define a list called clfs containing the two classifiers logreg and dt\n",
    "# clfs = [logreg, dt]\n",
    "\n",
    "# # Review the decision regions of the two classifiers\n",
    "# plot_labeled_decision_regions(X_test, y_test, clfs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The growth of an unconstrained classification tree followed a few simple rules:\n",
    "- The existence of a node depends on the state of its predecessors.\n",
    "- The impurity of a node can be determined using different criteria such as entropy and the gini-index.\n",
    "- When the information gain resulting from splitting a node is null, the node is declared as a leaf.\n",
    "- When an internal node is split, the split is performed in such a way so that information gain is maximized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import DecisionTreeClassifier from sklearn.tree.\n",
    "- Instantiate a DecisionTreeClassifier dt_entropy with a maximum depth of 8.\n",
    "- Set the information criterion to 'entropy'.\n",
    "- Fit dt_entropy on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import DecisionTreeClassifier from sklearn.tree\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# # Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "# dt_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=8, random_state=1)\n",
    "\n",
    "# # Fit dt_entropy to the training set\n",
    "# dt_entropy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import accuracy_score from sklearn.metrics.\n",
    "- Predict the test set labels of dt_entropy and assign the result to y_pred.\n",
    "- Evaluate the test set accuracy of dt_entropy and assign the result to accuracy_entropy.\n",
    "- Review accuracy_entropy and accuracy_gini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import accuracy_score from sklearn.metrics\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Use dt_entropy to predict test set labels\n",
    "# y_pred= dt_entropy.predict(X_test)\n",
    "\n",
    "# # Evaluate accuracy_entropy\n",
    "# accuracy_entropy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# # Print accuracy_entropy\n",
    "# print(f'Accuracy achieved by using entropy: {accuracy_entropy:.3f}')\n",
    "\n",
    "# # Print accuracy_gini\n",
    "# print(f'Accuracy achieved by using the gini index: {accuracy_gini:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import DecisionTreeRegressor from sklearn.tree.\n",
    "- Instantiate a DecisionTreeRegressor dt with maximum depth 8 and min_samples_leaf set to 0.13.\n",
    "- Fit dt to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import DecisionTreeRegressor from sklearn.tree\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# # Instantiate dt\n",
    "# dt = DecisionTreeRegressor(max_depth=8,\n",
    "#              min_samples_leaf=0.13,\n",
    "#             random_state=3)\n",
    "\n",
    "# # Fit dt to the training set\n",
    "# dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the function mean_squared_error as MSE from sklearn.metrics.\n",
    "- Predict the test set labels and assign the output to y_pred.\n",
    "- Compute the test set MSE by calling MSE and assign the result to mse_dt.\n",
    "- Compute the test set RMSE and assign it to rmse_dt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import mean_squared_error from sklearn.metrics as MSE\n",
    "# from sklearn.metrics import mean_squared_error as MSE\n",
    "# import numpy as np\n",
    "\n",
    "# # Compute y_pred\n",
    "# y_pred = dt.predict(X_test)\n",
    "\n",
    "# # Compute mse_dt\n",
    "# mse_dt = MSE(y_test, y_pred)\n",
    "\n",
    "# # Compute rmse_dt\n",
    "# rmse_dt = np.sqrt(mse_dt)\n",
    "\n",
    "# # Print rmse_dt\n",
    "# print(\"Test set RMSE of dt: {:.2f}\".format(rmse_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predict test set labels using the linear regression model (lr) and assign the result to y_pred_lr.\n",
    "- Compute the test set MSE and assign the result to mse_lr.\n",
    "- Compute the test set RMSE and assign the result to rmse_lr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict test set labels \n",
    "# y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# # Compute mse_lr\n",
    "# mse_lr = MSE(y_test, y_pred_lr)\n",
    "\n",
    "# # Compute rmse_lr\n",
    "# rmse_lr = mse_lr ** (1/2)\n",
    "\n",
    "# # Print rmse_lr\n",
    "# print('Linear Regression test set RMSE: {:.2f}'.format(rmse_lr))\n",
    "\n",
    "# # Print rmse_dt\n",
    "# print('Regression Tree test set RMSE: {:.2f}'.format(rmse_dt))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fef59229a6e1ff5434759995be53a28a25493efd6d26eb6c004eefe62e31083"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('env_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
