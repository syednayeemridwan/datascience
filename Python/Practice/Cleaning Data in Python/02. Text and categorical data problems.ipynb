{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the categories DataFrame and take a close look at all possible correct categories of the survey columns.\n",
    "- Print the unique values of the survey columns in airlines using the .unique() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        cleanliness           safety          satisfaction\n",
      "0             Clean          Neutral        Very ...      \n",
      "1           Average        Very safe             ...      \n",
      "2    Somewhat clean    Somewhat safe    Somewhat ...      \n",
      "3    Somewhat dirty      Very unsafe  Somewhat un...      \n",
      "4             Dirty  Somewhat unsafe      Very un...      \n",
      "Cleanliness:  ['Clean' 'Average' 'Somewhat clean' 'Somewhat dirty' 'Dirty'] \n",
      "\n",
      "Safety:  ['Neutral' 'Very safe' 'Somewhat safe' 'Very unsafe' 'Somewhat unsafe'] \n",
      "\n",
      "Satisfaction:  ['Very satisfied' 'Neutral' 'Somewhat satsified' 'Somewhat unsatisfied'\n",
      " 'Very unsatisfied'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "categories = pd.read_csv(\"cleanliness.csv\")\n",
    "airlines = pd.read_csv(\"airlines_final.csv\")\n",
    "\n",
    "# Print categories DataFrame\n",
    "print(categories)\n",
    "\n",
    "# Print unique values of survey columns in airlines\n",
    "print('Cleanliness: ', airlines['cleanliness'].unique(), \"\\n\")\n",
    "print('Safety: ', airlines['safety'].unique(), \"\\n\")\n",
    "print('Satisfaction: ', airlines['satisfaction'].unique(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the output. Out of the cleanliness, safety and satisfaction columns, which one has an inconsistent category and what is it?\n",
    "- cleanliness because it has an Unacceptable category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a set out of the cleanliness column in airlines using set() and find the inconsistent category by finding the difference in the cleanliness column of categories.\n",
    "- Find rows of airlines with a cleanliness value not in categories and print the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the cleanliness category in airlines not in categories\n",
    "# cat_clean = set(airlines['cleanliness']).difference(categories['cleanliness'])\n",
    "\n",
    "# # Find rows with that category\n",
    "# cat_clean_rows = airlines['cleanliness'].isin(cat_clean)\n",
    "\n",
    "# # Print rows with inconsistent category\n",
    "# print(airlines[cat_clean_rows])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the rows with the consistent categories of cleanliness only.\n",
    "- USE TILDER TO REVERSE TO SUBSET CONDITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(airlines[~cat_clean_rows])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the unique values in dest_region and dest_size respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east']\n",
      "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
      " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n"
     ]
    }
   ],
   "source": [
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the output, what do you think is the problem with these columns?\n",
    "- The dest_region column has inconsistent values due to capitalization and has one value that needs to be remapped.\n",
    "- The dest_size column has only inconsistent values due to leading and trailing spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Change the capitalization of all values of dest_region to lowercase.\n",
    "- Replace the 'eur' with 'europe' in dest_region using the .replace() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east']\n",
      "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
      " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n"
     ]
    }
   ],
   "source": [
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower()\n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Strip white spaces from the dest_size column using the .strip() method.\n",
    "- Verify that the changes have been into effect by printing the unique values of the columns using .unique() ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asia' 'canada/mexico' 'west us' 'east us' 'midwest us' 'middle east'\n",
      " 'europe' 'central/south america' 'australia/new zealand']\n",
      "['Hub' 'Small' 'Medium' 'Large']\n",
      "['Hub' 'Small' 'Medium' 'Large']\n",
      "['asia' 'canada/mexico' 'west us' 'east us' 'midwest us' 'middle east'\n",
      " 'europe' 'central/south america' 'australia/new zealand']\n"
     ]
    }
   ],
   "source": [
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower() \n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})\n",
    "\n",
    "# Remove white spaces from `dest_size`\n",
    "airlines['dest_size'] = airlines['dest_size'].str.strip()\n",
    "\n",
    "# Verify changes have been effected\n",
    "print(airlines['dest_size'].unique())\n",
    "print(airlines['dest_region'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create the ranges and labels for the wait_type column mentioned in the description.\n",
    "- Create the wait_type column by from wait_min by using pd.cut(), while inputting label_ranges and label_names in the correct arguments.\n",
    "- Create the mapping dictionary mapping weekdays to 'weekday' and weekend days to 'weekend'.\n",
    "- Create the day_week column by using .replace()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Create ranges for categories\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = ['short', 'medium', 'long']\n",
    "\n",
    "# Create wait_type column\n",
    "airlines['wait_type'] = pd.cut(airlines['wait_min'], bins = label_ranges, \n",
    "                                labels = label_names)\n",
    "\n",
    "# Create mappings and replace\n",
    "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', \n",
    "            'Thursday': 'weekday', 'Friday': 'weekday', \n",
    "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
    "\n",
    "airlines['day_week'] = airlines['day'].replace(mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove \"Dr.\", \"Mr.\", \"Miss\" and \"Ms.\" from full_name by replacing them with an empty string \"\" in that order.\n",
    "- Run the assert statement using .str.contains() that tests whether full_name still contains any of the honorifics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace \"Dr.\" with empty string \"\"\n",
    "# airlines['full_name'] = airlines['full_name'].str.replace(\"Dr.\",\"\")\n",
    "\n",
    "# # Replace \"Mr.\" with empty string \"\"\n",
    "# airlines['full_name'] = airlines['full_name'].str.replace(\"Mr.\",\"\")\n",
    "\n",
    "# # Replace \"Miss\" with empty string \"\"\n",
    "# airlines['full_name'] = airlines['full_name'].str.replace(\"Miss\",\"\")\n",
    "\n",
    "# # Replace \"Ms.\" with empty string \"\"\n",
    "# airlines['full_name'] = airlines['full_name'].str.replace(\"Ms.\",\"\")\n",
    "\n",
    "# # Assert that full_name has no honorifics\n",
    "# assert airlines['full_name'].str.contains('Ms.|Mr.|Miss|Dr.').any() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the airlines DataFrame, store the length of each instance in the survey_response column in resp_length by using .str.len().\n",
    "- Isolate the rows of airlines with resp_length higher than 40.\n",
    "- Assert that the smallest survey_response length in airlines_survey is now bigger than 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store length of each row in survey_response column\n",
    "# resp_length = airlines['survey_response'].str.len()\n",
    "\n",
    "# # Find rows in airlines where resp_length > 40\n",
    "# airlines_survey = airlines[resp_length > 40]\n",
    "\n",
    "# # Assert minimum survey_response length is > 40\n",
    "# assert airlines_survey['survey_response'].str.len().min() > 40\n",
    "\n",
    "# # Print new survey_response column\n",
    "# print(airlines_survey['survey_response'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fef59229a6e1ff5434759995be53a28a25493efd6d26eb6c004eefe62e31083"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('env_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
