{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import Pipeline from sklearn.pipeline.\n",
    "- Create training and test sets using the numeric data only. Do this by specifying sample_df[['numeric']] in train_test_split().\n",
    "- Instantiate a pipeline as pl by adding the classifier step. Use a name of 'clf' and the same classifier from Chapter 2: OneVsRestClassifier(LogisticRegression()).\n",
    "- Fit your pipeline to the training data and compute its accuracy to see it in action! Since this is toy data, you'll use the default scoring method for now. In the next chapter, you'll return to log loss scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import Pipeline\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# # Import other necessary modules\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# # Split and select numeric data only, no nans \n",
    "# X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric']],\n",
    "#                                                     pd.get_dummies(sample_df['label']), \n",
    "#                                                     random_state=22)\n",
    "\n",
    "# # Instantiate Pipeline object: pl\n",
    "# pl = Pipeline([\n",
    "#         ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "#     ])\n",
    "\n",
    "# # Fit the pipeline to the training data\n",
    "# pl.fit(X_train, y_train)\n",
    "\n",
    "# # Compute and print accuracy\n",
    "# accuracy = pl.score(X_test, y_test)\n",
    "# print(\"\\nAccuracy on sample data - numeric, no nans: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import Imputer from sklearn.preprocessing.\n",
    "- Create training and test sets by selecting the correct subset of sample_df: 'numeric' and 'with_missing'.\n",
    "- Add the tuple ('imp', Imputer()) to the correct position in the pipeline. Pipeline processes steps sequentially, so the imputation step should come before the classifier step.\n",
    "- Complete the .fit() and .score() methods to fit the pipeline to the data and compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the Imputer object\n",
    "# from sklearn.preprocessing import Imputer\n",
    "\n",
    "# # Create training and test sets using only numeric data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric' , 'with_missing']],\n",
    "#                                                     pd.get_dummies(sample_df['label']), \n",
    "#                                                     random_state=456)\n",
    "\n",
    "# # Insantiate Pipeline object: pl\n",
    "# pl = Pipeline([\n",
    "#         ('imp', Imputer()),\n",
    "#         ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "#     ])\n",
    "\n",
    "# # Fit the pipeline to the training data\n",
    "# pl.fit(X_train, y_train)\n",
    "\n",
    "# # Compute and print accuracy\n",
    "# accuracy = pl.score(X_test, y_test)\n",
    "# print(\"\\nAccuracy on sample data - all numeric, incl nans: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import CountVectorizer from sklearn.feature_extraction.text.\n",
    "- Create training and test sets by selecting the correct subset of sample_df: 'text'.\n",
    "- Add the CountVectorizer step (with the name 'vec') to the correct position in the pipeline.\n",
    "- Fit the pipeline to the training data and compute its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the CountVectorizer\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# # Split out only the text data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(sample_df['text'],\n",
    "#                                                     pd.get_dummies(sample_df['label']), \n",
    "#                                                     random_state=456)\n",
    "\n",
    "# # Instantiate Pipeline object: pl\n",
    "# pl = Pipeline([\n",
    "#         ('vec', CountVectorizer()),\n",
    "#         ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "#     ])\n",
    "\n",
    "# # Fit to the training data\n",
    "# pl.fit(X_train, y_train)\n",
    "\n",
    "# # Compute and print accuracy\n",
    "# accuracy = pl.score(X_test, y_test)\n",
    "# print(\"\\nAccuracy on sample data - just text data: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the selector get_text_data by using a lambda function and FunctionTransformer() to obtain all 'text' columns.\n",
    "- Compute the selector get_numeric_data by using a lambda function and FunctionTransformer() to obtain all the numeric columns (including missing data). These are 'numeric' and 'with_missing'.\n",
    "- Fit and transform get_text_data using the .fit_transform() method with sample_df as the argument.\n",
    "- Fit and transform get_numeric_data using the same approach as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import FunctionTransformer\n",
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# # Obtain the text data: get_text_data\n",
    "# get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\n",
    "\n",
    "# # Obtain the numeric data: get_numeric_data\n",
    "# get_numeric_data = FunctionTransformer(lambda x: x[['numeric' , 'with_missing']], validate=False)\n",
    "\n",
    "# # Fit and transform the text data: just_text_data\n",
    "# just_text_data = get_text_data.fit_transform(sample_df)\n",
    "\n",
    "# # Fit and transform the numeric data: just_numeric_data\n",
    "# just_numeric_data = get_numeric_data.fit_transform(sample_df)\n",
    "\n",
    "# # Print head to check results\n",
    "# print('Text Data')\n",
    "# print(just_text_data.head())\n",
    "# print('\\nNumeric Data')\n",
    "# print(just_numeric_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the process_and_join_features:\n",
    "- Add the steps ('selector', get_numeric_data) and ('imputer', Imputer()) to the 'numeric_features' preprocessing step.\n",
    "- Add the equivalent steps for the text_features preprocessing step. That is, use get_text_data and a CountVectorizer step with the name 'vectorizer'.\n",
    "- Add the transform step process_and_join_features to 'union' in the main pipeline, pl.\n",
    "- Hit submit to see the pipeline in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import FeatureUnion\n",
    "# from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# # Split using ALL data in sample_df\n",
    "# X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing', 'text']],\n",
    "#                                                     pd.get_dummies(sample_df['label']), \n",
    "#                                                     random_state=22)\n",
    "\n",
    "# # Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "# process_and_join_features = FeatureUnion(\n",
    "#             transformer_list = [\n",
    "#                 ('numeric_features', Pipeline([\n",
    "#                     ('selector', get_numeric_data),\n",
    "#                     ('imputer',  Imputer())\n",
    "#                 ])),\n",
    "#                 ('text_features', Pipeline([\n",
    "#                     ('selector', get_text_data),\n",
    "#                     ('vectorizer',  CountVectorizer())\n",
    "#                 ]))\n",
    "#              ]\n",
    "#         )\n",
    "\n",
    "# # Instantiate nested pipeline: pl\n",
    "# pl = Pipeline([\n",
    "#         ('union', process_and_join_features),\n",
    "#         ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "#     ])\n",
    "\n",
    "\n",
    "# # Fit pl to the training data\n",
    "# pl.fit(X_train, y_train)\n",
    "\n",
    "# # Compute and print accuracy\n",
    "# accuracy = pl.score(X_test, y_test)\n",
    "# print(\"\\nAccuracy on sample data - all data: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Complete the call to multilabel_train_test_split() by selecting df[NON_LABELS].\n",
    "- Compute get_text_data by using FunctionTransformer() and passing in combine_text_columns. Be sure to also specify validate=False.\n",
    "- Use FunctionTransformer() to compute get_numeric_data. In the lambda function, select out the NUMERIC_COLUMNS of x. Like you did when computing get_text_data, also specify validate=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define combine_text_columns()\n",
    "# def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n",
    "#     \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "#     # Drop non-text columns that are in the df\n",
    "#     to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "#     text_data = data_frame.drop(to_drop,axis = 1)\n",
    "    \n",
    "#     # Replace nans with blanks\n",
    "#     text_data.fillna('', inplace = True)\n",
    "    \n",
    "#     # Join all text items in a row that have a space in between\n",
    "#     return text_data.apply(lambda x: \" \".join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import FunctionTransformer\n",
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# # Get the dummy encoding of the labels\n",
    "# dummy_labels = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# # Get the columns that are features in the original df\n",
    "# NON_LABELS = [c for c in df.columns if c not in LABELS]\n",
    "\n",
    "# # Split into training and test sets\n",
    "# X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABELS],\n",
    "#                                                                dummy_labels,\n",
    "#                                                                0.2, \n",
    "#                                                                seed=123)\n",
    "\n",
    "# # Preprocess the text data: get_text_data\n",
    "# get_text_data = FunctionTransformer(combine_text_columns ,validate=False)\n",
    "\n",
    "# # Preprocess the numeric data: get_numeric_data\n",
    "# get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Complete the 'numeric_features' transform with the following steps:\n",
    "- get_numeric_data, with the name 'selector'.\n",
    "- Imputer(), with the name 'imputer'.\n",
    "- Complete the 'text_features' transform with the following steps:\n",
    "- get_text_data, with the name 'selector'.\n",
    "- CountVectorizer(), with the name 'vectorizer'.\n",
    "- Fit the pipeline to the training data.\n",
    "- Hit submit to compute the accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Complete the pipeline: pl\n",
    "# pl = Pipeline([\n",
    "#         ('union', FeatureUnion(\n",
    "#             transformer_list = [\n",
    "#                 ('numeric_features', Pipeline([\n",
    "#                     ('selector', get_numeric_data),\n",
    "#                     ('imputer', Imputer())\n",
    "#                 ])),\n",
    "#                 ('text_features', Pipeline([\n",
    "#                     ('selector', get_text_data),\n",
    "#                     ('vectorizer', CountVectorizer())\n",
    "#                 ]))\n",
    "#              ]\n",
    "#         )),\n",
    "#         ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "#     ])\n",
    "\n",
    "# # Fit to the training data\n",
    "# pl.fit(X_train, y_train)\n",
    "\n",
    "# # Compute and print accuracy\n",
    "# accuracy = pl.score(X_test, y_test)\n",
    "# print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the RandomForestClassifier from sklearn.ensemble.\n",
    "- Add a RandomForestClassifier() step named 'clf' to the pipeline.\n",
    "- Hit submit to fit the pipeline to the training data and compute its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import random forest classifer\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Edit model step in pipeline\n",
    "# pl = Pipeline([\n",
    "#         ('union', FeatureUnion(\n",
    "#             transformer_list = [\n",
    "#                 ('numeric_features', Pipeline([\n",
    "#                     ('selector', get_numeric_data),\n",
    "#                     ('imputer', Imputer())\n",
    "#                 ])),\n",
    "#                 ('text_features', Pipeline([\n",
    "#                     ('selector', get_text_data),\n",
    "#                     ('vectorizer', CountVectorizer())\n",
    "#                 ]))\n",
    "#              ]\n",
    "#         )),\n",
    "#         ('clf', RandomForestClassifier())\n",
    "#     ])\n",
    "\n",
    "# # Fit to the training data\n",
    "# pl.fit(X_train, y_train)\n",
    "\n",
    "# # Compute and print accuracy\n",
    "# accuracy = pl.score(X_test, y_test)\n",
    "# print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the RandomForestClassifier from sklearn.ensemble.\n",
    "- Add a RandomForestClassifier() step with n_estimators=15 to the pipeline with a name of 'clf'.\n",
    "- Hit submit to fit the pipeline to the training data and compute its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import RandomForestClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Add model step to pipeline: pl\n",
    "# pl = Pipeline([\n",
    "#         ('union', FeatureUnion(\n",
    "#             transformer_list = [\n",
    "#                 ('numeric_features', Pipeline([\n",
    "#                     ('selector', get_numeric_data),\n",
    "#                     ('imputer', Imputer())\n",
    "#                 ])),\n",
    "#                 ('text_features', Pipeline([\n",
    "#                     ('selector', get_text_data),\n",
    "#                     ('vectorizer', CountVectorizer())\n",
    "#                 ]))\n",
    "#              ]\n",
    "#         )),\n",
    "#         ('clf', RandomForestClassifier(n_estimators = 15))\n",
    "#     ])\n",
    "\n",
    "# # Fit to the training data\n",
    "# pl.fit(X_train, y_train)\n",
    "\n",
    "# # Compute and print accuracy\n",
    "# accuracy = pl.score(X_test, y_test)\n",
    "# print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fef59229a6e1ff5434759995be53a28a25493efd6d26eb6c004eefe62e31083"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('env_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
